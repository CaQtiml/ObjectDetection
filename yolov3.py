# -*- coding: utf-8 -*-
"""YOLOv3

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1y7wjO4KFfh20M889OUqFH6A-jK6-hChg
"""

import tensorflow as tf
from tensorflow.keras import Model
from tensorflow.keras.layers import BatchNormalization, Conv2D, Input, ZeroPadding2D, LeakyReLU, UpSampling2D
import numpy as np
import cv2
import streamlit as st
import os

def parse_cfg(cfgfile):
    with open(cfgfile, 'r') as file:
        lines = [line.rstrip('\n') for line in file if line != '\n' and line[0] != '#']
    holder = {}
    blocks = []
    for line in lines:
        if line[0] == '[':
            line = 'type=' + line[1:-1].rstrip()
            if len(holder) != 0:
                blocks.append(holder)
                holder = {}
        key, value = line.split("=")
        holder[key.rstrip()] = value.lstrip()
    blocks.append(holder)
    return blocks

def YOLOv3Net(cfgfile, model_size, num_classes):
    blocks = parse_cfg(cfgfile)
    outputs = {}
    output_filters = []
    filters = 0
    out_pred = []
    scale = 0

    inputs = input_image = Input(shape=model_size)
    inputs = inputs / 255.0
    for i, block in enumerate(blocks[1:]):
      if (block["type"] == "convolutional"):
        activations = block["activation"]
        filters = int(block["filters"])
        kernel_size = int(block["size"])
        strides = int(block["stride"])
        if strides > 1:
          inputs = ZeroPadding2D(((1,0),(1,0)))(inputs)
        inputs = Conv2D(filters,
                        kernel_size,
                        strides=strides,
                        padding="valid" if strides>1 else "same",
                        name='conv_' + str(i),
                        use_bias=False if ("batch_normalize" in block) else True)(inputs)
        if "batch_normalize" in block:
          inputs = BatchNormalization(name='bnorm_' + str(i))(inputs)
          inputs = LeakyReLU(alpha=0.1, name='leaky_' + str(i))(inputs)
      elif (block["type"] == "upsample"):
        stride = int(block["stride"])
        inputs = UpSampling2D(stride)(inputs)
      elif (block["type"] == "route"):
        block["layers"] = block["layers"].split(',')
        start = int(block["layers"][0])
        if len(block["layers"]) > 1:
          end = int(block["layers"][1]) - i
          filters = output_filters[i + start] + output_filters[end]
          inputs = tf.concat([outputs[i + start], outputs[i + end]], axis=-1)
        else:
          filters = output_filters[i + start]
          inputs = outputs[i + start]
      elif block["type"] == "shortcut":
        from_ = int(block["from"])
        inputs = outputs[i - 1] + outputs[i + from_]
      elif block["type"] == "yolo":
        mask = block["mask"].split(",")
        mask = [int(x) for x in mask]
        anchors = block["anchors"].split(",")
        anchors = [int(a) for a in anchors]
        anchors = [(anchors[i], anchors[i + 1]) for i in range(0, len(anchors), 2)]
        anchors = [anchors[i] for i in mask]
        n_anchors = len(anchors)


        out_shape = inputs.get_shape().as_list()
        inputs = tf.reshape(inputs, [-1, n_anchors * out_shape[1] * out_shape[2], 5 + num_classes])

        box_centers = inputs[:, :, 0:2]
        box_shapes = inputs[:, :, 2:4]
        confidence = inputs[:, :, 4:5]
        classes = inputs[:, :, 5:num_classes + 5]


        box_centers = tf.sigmoid(box_centers)
        confidence = tf.sigmoid(confidence)
        classes = tf.sigmoid(classes)
        anchors = tf.tile(anchors, [out_shape[1] * out_shape[2], 1])
        box_shapes = tf.exp(box_shapes) * tf.cast(anchors, dtype=tf.float32) # element-wise multiplication


        x = tf.range(out_shape[1], dtype=tf.float32)
        y = tf.range(out_shape[2], dtype=tf.float32)
        cx, cy = tf.meshgrid(x, y)
        cx = tf.reshape(cx, (-1, 1))
        cy = tf.reshape(cy, (-1, 1))
        cxy = tf.concat([cx, cy], axis=-1)
        cxy = tf.tile(cxy, [1, n_anchors])
        cxy = tf.reshape(cxy, [1, -1, 2])
        strides = (input_image.shape[1] // out_shape[1],
                    input_image.shape[2] // out_shape[2])
        box_centers = (box_centers + cxy) * strides
        prediction = tf.concat([box_centers, box_shapes, confidence, classes], axis=-1)


        if scale:
          out_pred = tf.concat([out_pred, prediction], axis=1)
        else:
          out_pred = prediction
          scale = 1

      outputs[i] = inputs
      output_filters.append(filters)

    model = Model(input_image, out_pred)
    return model

def load_weights(model,cfgfile,weightfile):
    fp = open(weightfile, "rb")
    np.fromfile(fp, dtype=np.int32, count=5)
    blocks = parse_cfg(cfgfile)
    for i, block in enumerate(blocks[1:]):
        if (block["type"] == "convolutional"):
            conv_layer = model.get_layer('conv_' + str(i))
            filters = conv_layer.filters
            k_size = conv_layer.kernel_size[0]
            in_dim = conv_layer.input_shape[-1] 
            if "batch_normalize" in block:
                norm_layer = model.get_layer('bnorm_' + str(i))
                size = np.prod(norm_layer.get_weights()[0].shape)
                bn_weights = np.fromfile(fp, dtype=np.float32, count=4 * filters)
                bn_weights = bn_weights.reshape((4, filters))[[1, 0, 2, 3]]
            else:
                conv_bias = np.fromfile(fp, dtype=np.float32, count=filters)
            conv_shape = (filters, in_dim, k_size, k_size)
            conv_weights = np.fromfile(
                fp, dtype=np.float32, count=np.product(conv_shape))
            conv_weights = conv_weights.reshape(
                conv_shape).transpose([2, 3, 1, 0])
            if "batch_normalize" in block:
                norm_layer.set_weights(bn_weights)
                conv_layer.set_weights([conv_weights])
            else:
                conv_layer.set_weights([conv_weights, conv_bias])
    assert len(fp.read()) == 0, 'failed to read all data'
    fp.close()

def non_max_suppression(inputs, model_size, max_output_size, 
                        max_output_size_per_class, iou_threshold, confidence_threshold):
    bbox, confs, class_probs = tf.split(inputs, [4, 1, -1], axis=-1)
    bbox=bbox/model_size[0]
    scores = confs * class_probs
    boxes, scores, classes, valid_detections = tf.image.combined_non_max_suppression(
        boxes=tf.reshape(bbox, (tf.shape(bbox)[0], -1, 1, 4)),
        scores=tf.reshape(scores, (tf.shape(scores)[0], -1, tf.shape(scores)[-1])),
        max_output_size_per_class=max_output_size_per_class,
        max_total_size=max_output_size,
        iou_threshold=iou_threshold,
        score_threshold=confidence_threshold
    )
    return boxes, scores, classes, valid_detections

def resize_image(inputs, modelsize):
    inputs= tf.image.resize(inputs, modelsize)
    return inputs

def load_class_names(file_name):
    with open(file_name, 'r') as f:
        class_names = f.read().splitlines()
    return class_names

def output_boxes(inputs,model_size, max_output_size, max_output_size_per_class, 
                 iou_threshold, confidence_threshold):
    center_x, center_y, width, height, confidence, classes = tf.split(inputs, [1, 1, 1, 1, 1, -1], axis=-1)
    top_left_x = center_x - width / 2.0
    top_left_y = center_y - height / 2.0
    bottom_right_x = center_x + width / 2.0
    bottom_right_y = center_y + height / 2.0
    inputs = tf.concat([top_left_x, top_left_y, bottom_right_x,
                        bottom_right_y, confidence, classes], axis=-1)
    boxes_dicts = non_max_suppression(inputs, model_size, max_output_size, 
                                      max_output_size_per_class, iou_threshold, confidence_threshold)
    return boxes_dicts

def genColorDict():
  color_dict = {}
  for i in range(85):
    color = tuple(np.random.choice(range(256), size=3))
    color_dict[i] = color
  return color_dict

def draw_outputs(img, boxes, objectness, classes, nums, class_names):
    boxes, objectness, classes, nums = boxes[0], objectness[0], classes[0], nums[0]
    print(nums)
    colorDict = genColorDict()
    boxes=np.array(boxes)
    for i in range(nums):
        x1y1 = tuple((boxes[i,0:2] * [img.shape[1],img.shape[0]]).astype(np.int32))
        x2y2 = tuple((boxes[i,2:4] * [img.shape[1],img.shape[0]]).astype(np.int32))
        (col1,col2,col3) = colorDict[int(classes[i])]
        col1 = int(col1)
        col2 = int(col2)
        col3 = int(col3)
        # print(int(classes[i]),col1,col2,col3)
        img = cv2.rectangle(img, (x1y1), (x2y2), (col1,col2,col3), 2)
        img = cv2.putText(img, 
                          f'{class_names[int(classes[i])]} {objectness[i]:.4f}',
                          (x1y1), 
                          cv2.FONT_HERSHEY_PLAIN, 
                          1, (0, 0, 255), 2)
    return img


model_size = (416, 416,3)
num_classes = 80
class_name = 'coco.names'
max_output_size = 40
max_output_size_per_class= 20
iou_threshold = 0.5
confidence_threshold = 0.5
cfgfile = 'yolov3.cfg'
weight = "yolov3.weights"
image = None
path = os.path.join("./app/","model_yolov3.h5")

# model = YOLOv3Net(cfgfile,model_size,num_classes)
# load_weights(model,cfgfile,weight)
loaded_model = tf.keras.models.load_model(path)
class_names = load_class_names(class_name)
uploaded_file = st.file_uploader("Choose a file")
if uploaded_file is not None:
    image = np.asarray(bytearray(uploaded_file.getvalue()), dtype="uint8")
    image = cv2.imdecode(image, cv2.IMREAD_ANYCOLOR)
    image = cv2.cvtColor(image , cv2.COLOR_BGR2RGB)
    image = np.array(image)
    image = tf.expand_dims(image, 0)
    resized_frame = resize_image(image, (model_size[0],model_size[1]))
    pred = loaded_model.predict(resized_frame)
    boxes, scores, classes, nums = output_boxes(
        pred, model_size,
        max_output_size=max_output_size,
        max_output_size_per_class=max_output_size_per_class,
        iou_threshold=iou_threshold,
        confidence_threshold=confidence_threshold)
    image = np.squeeze(image)
    img = draw_outputs(image, boxes, scores, classes, nums, class_names)
    st.image(img, caption='Sunrise by the mountains')


